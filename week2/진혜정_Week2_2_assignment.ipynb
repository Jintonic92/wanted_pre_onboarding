{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592U6lXs3d2t"
      },
      "source": [
        "# Week2_2 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- \"네이버 영화 감성 분류\" 데이터를 불러와 `pandas` 라이브러리를 사용해 **전처리** 할 수 있다.\n",
        "- 적은 데이터로도 높은 성능을 내기 위해, pre-trained `BERT` 모델 위에 1개의 hidden layer를 쌓아 **fine-tuning**할 수 있다.\n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- 토큰화된 학습 데이터를 배치 단위로 갖는 **traindata iterator**를 구현할 수 있다. \n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- **loss와 optimizer 함수**를 사용할 수 있다. \n",
        "- traindata iterator를 for loop 돌며 **fine-tuning** 할 수 있다.\n",
        "- fine-tuning의 2가지 방법론을 비교할 수 있다. \n",
        "  - BERT 파라미터를 **freeze** 한 채 fine-tuning (Vision에서 주로 사용하는 방법론)\n",
        "  - BERT 파라미터를 **unfreeze** 한 채 fine-tuning (NLP에서 주로 사용하는 방법론)\n",
        "\n",
        "\n",
        "### Reference\n",
        "- [huggingface 한국어 오픈소스 모델](https://huggingface.co/models?language=ko&sort=downloads&search=bert)\n",
        "- [transformer BertForSequenceClassification 소스 코드](https://github.com/huggingface/transformers/blob/v4.15.0/src/transformers/models/bert/modeling_bert.py#L1501)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSX-wQA1RD1h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Reyt-HvLnJv"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUR6vb3L3d2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adee2f10-a2e4-4097-df1b-b79651115f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "  print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93M8XmjLnJw"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0REKl4EvT9G1"
      },
      "source": [
        "### 데이터 다운로드 및 DataFrame 형태로 불러오기\n",
        "- 내 구글 드라이브에 데이터를 다운받은 후 코랩에 드라이브를 마운트하면 데이터를 영구적으로 사용할 수 있음.\n",
        "- [네이버영화감성분류](https://github.com/e9t/nsmc)\n",
        "  - trainset: 150,000 \n",
        "  - testset: 50,000 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEWUggR1R9rS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aba0f92-07a2-40e0-89f7-594442b68fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "id": "T3GWIEFgiatC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rov1s8IxSLqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f341a01b-f331-4755-b3f4-21eebdc93a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjPGnbEjVYmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5619250f-5697-49de-9cef-8e75161e8b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nsmc' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# 데이터 다운로드\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SueG9v14YbgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4686df-4e33-494d-dab3-1df7fd487b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My current directory : /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "_CUR_DIR = os.path.abspath(os.curdir)\n",
        "print(f\"My current directory : {_CUR_DIR}\")\n",
        "_DATA_DIR = os.path.join(_CUR_DIR, \"nsmc\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lKlTZEITjHdS",
        "outputId": "c7d281e4-85d3-4660-de15-af45132b53ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive'"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J6KQ8dzaHBi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "58dbe0b9-b5c2-44bb-c71e-3d17f9aeab71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c3fc0191-9d8f-4f65-ae73-e016809c8722\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>6222902</td>\n",
              "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>8549745</td>\n",
              "      <td>평점이 너무 낮아서...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>9311800</td>\n",
              "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>2376369</td>\n",
              "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>9619869</td>\n",
              "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3fc0191-9d8f-4f65-ae73-e016809c8722')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3fc0191-9d8f-4f65-ae73-e016809c8722 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3fc0191-9d8f-4f65-ae73-e016809c8722');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              id                                           document  label\n",
              "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
              "...          ...                                                ...    ...\n",
              "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
              "149996   8549745                                      평점이 너무 낮아서...      1\n",
              "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
              "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
              "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
              "\n",
              "[150000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "# nsmc/ratings_train.txt를 DataFrame 형태로 불러오기\n",
        "df = pd.read_table('nsmc/ratings_train.txt')\n",
        "print(type(df))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cUsoBEPahlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0320c5-26c0-4a83-c056-6cd4ef84c578"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "# 데이터 크기 확인\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic3k9CORaXzM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "06e8a002-22d0-4151-8d8a-8d8543ba7895"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e279e3e7-ac34-4c0c-99d8-8292fd45dbcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e279e3e7-ac34-4c0c-99d8-8292fd45dbcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e279e3e7-ac34-4c0c-99d8-8292fd45dbcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e279e3e7-ac34-4c0c-99d8-8292fd45dbcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "# 데이터 일부 확인\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA1F0tHWLnJz"
      },
      "source": [
        "### 데이터 결측치 제거 및 데이터 수 줄이기 \n",
        "- 학습 데이터 수는 150,000개로 매우 많은 양이다. 하지만 우리가 실생활에서 마주할 데이터는 이렇게 많지 않다. 이 때 유용하게 사용되는 것이 **fine-tuning** 학습 방법이다.   \n",
        "- Fine-tuning은 단어의 의미를 이미 충분히 학습한 모델 (여기서는 **BERT**)을 가져와 그 위에 추가적인 Nueral Network 레이어를 쌓은 후 학습하는 방법론이다. 이미 BERT가 단어의 의미를 충분히 학습했기 때문에 **적은 데이터**로 학습해도 우수한 성능을 낼 수 있다는 장점이 있다. \n",
        "- **데이터의 label의 비율이 5:5를 유지하면서** 학습 데이터 수를 150,000개에서 1,000개로 줄이\b는 함수 `label_evenly_balanced_dataset_sampler`를 구현하라.\n",
        "  - 함수 정의 \n",
        "    - 입력 매개변수\n",
        "      - df : DataFrame\n",
        "      - n_sample : df에서 샘플링할 row의 개수 (여기서는 1000개로 정의한다)\n",
        "    - 조건\n",
        "      - label의 비율이 5:5를 유지할 수 있도록 샘플링한다.\n",
        "    - 반환값\n",
        "      - row의 개수가 1000개인 dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh9BSiSeMms7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2ab7f0-47a4-4bc9-f970-644e59fc4530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결측치 존재 T/F: True\n",
            "--------------\n",
            "ID 결측치 세부 위치 확인:\n",
            " Empty DataFrame\n",
            "Columns: [id, document, label]\n",
            "Index: []\n",
            "--------------\n",
            "Document 결측치 세부 위치 확인:\n",
            "              id document  label\n",
            "25857   2172111      NaN      1\n",
            "55737   6369843      NaN      1\n",
            "110014  1034280      NaN      0\n",
            "126782  5942978      NaN      0\n",
            "140721  1034283      NaN      0\n",
            "--------------\n",
            "Label 결측치 세부 위치 확인:\n",
            " Empty DataFrame\n",
            "Columns: [id, document, label]\n",
            "Index: []\n",
            "결측치 제거 후 결측치 존재 T/F: False\n"
          ]
        }
      ],
      "source": [
        "# df에서 결측치 (na 값) 제거\n",
        "print('결측치 존재 T/F:', df.isnull().values.any())\n",
        "print('--------------')\n",
        "print('ID 결측치 세부 위치 확인:\\n', df.loc[df.id.isnull()])\n",
        "print('--------------')\n",
        "print('Document 결측치 세부 위치 확인:\\n', df.loc[df.document.isnull()])\n",
        "print('--------------')\n",
        "print('Label 결측치 세부 위치 확인:\\n', df.loc[df.label.isnull()])\n",
        "df = df.dropna(how='any')\n",
        "print('결측치 제거 후 결측치 존재 T/F:', df.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ommF5KH4akCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ee24ec-de89-4503-d1da-8094af26a817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    75170\n",
              "1    74825\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "# label별 데이터 수 확인\n",
        "# pandas의 value_counts 함수 활용\n",
        "# 0 -> 부정 1 -> 긍정\n",
        "\n",
        "# pos 1, neg 0 \n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ii06wCsc107"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터 샘플 개수 설정\n",
        "\n",
        "n_sample = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrkhl69Dc-kr"
      },
      "outputs": [],
      "source": [
        "# 샘플링 함수 구현\n",
        "# random 모듈에서 제공되는 함수 활용\n",
        "# input: 학습 데이터 샘플 개수\n",
        "# output: 샘플링 데이터\n",
        "\n",
        "\n",
        "def label_evenly_balanced_dataset_sampler(df, sample_size):\n",
        "  \"\"\"\n",
        "  데이터 프레임의을 sample_size만큼 임의 추출해 새로운 데이터 프레임을 생성.\n",
        "  이 때, \"label\"열의 값들이 동일한 비율을 갖도록(5:5) 할 것.\n",
        "  \"\"\"\n",
        "  df1 = df.loc[df['label'] == 0]\n",
        "  df1 = df1.sample(int(sample_size/2))\n",
        "  df2 = df.loc[df['label'] == 1]\n",
        "  df2 = df2.sample(int(sample_size/2))\n",
        "\n",
        "\n",
        "  sample = pd.concat([df1,df2])\n",
        "\n",
        "  return sample\n",
        "\n",
        "sample_df = label_evenly_balanced_dataset_sampler(df, n_sample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jSlbAWdPp8vU",
        "outputId": "321557ff-5163-492b-fc20-7f7c1cd0a67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3b1b4de0-0162-4947-a1c9-dfd241bd17a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54904</th>\n",
              "      <td>7266425</td>\n",
              "      <td>심형래 영화보다 재미없나?...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65295</th>\n",
              "      <td>6805358</td>\n",
              "      <td>정말 지루하네.. 감상적인 장면이 너무 필요 이상으로 많아서 흥미가 너무 떨어짐..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103572</th>\n",
              "      <td>6822058</td>\n",
              "      <td>마눌님도 자고, 우리 애도 자고 결국엔 끝나기 20분전에 도망치듯 빠져나왔다..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102382</th>\n",
              "      <td>9837833</td>\n",
              "      <td>시나리오 수준이 참..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133343</th>\n",
              "      <td>5879324</td>\n",
              "      <td>2004년꺼를 이제 가지고와서 어쩌겟다는거지? 지금시대에 이런영화가 인정받을것같아?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37514</th>\n",
              "      <td>8494235</td>\n",
              "      <td>끝난 후에도 계속해서 잔잔하게 밀려오는 감동과 여운.. 특히 여주의 연기가 좋았고 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90946</th>\n",
              "      <td>8898595</td>\n",
              "      <td>치밀한 구성 막판이 조금 아쉬웠으나 매우 우수했다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117818</th>\n",
              "      <td>4405477</td>\n",
              "      <td>이거보고 진짜 감동먹엇어요ㅠㅠ특히 끝나갈때 남자 제자리걸음할때 ~!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144608</th>\n",
              "      <td>6991515</td>\n",
              "      <td>실화를 배경으로 했다고 합니다...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148841</th>\n",
              "      <td>10002192</td>\n",
              "      <td>원작을 안 읽어서인지 처음 기대한 건 유카와와 이시가미의 대결구도였다. 기대했던 건...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b1b4de0-0162-4947-a1c9-dfd241bd17a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b1b4de0-0162-4947-a1c9-dfd241bd17a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b1b4de0-0162-4947-a1c9-dfd241bd17a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              id                                           document  label\n",
              "54904    7266425                                  심형래 영화보다 재미없나?...      0\n",
              "65295    6805358     정말 지루하네.. 감상적인 장면이 너무 필요 이상으로 많아서 흥미가 너무 떨어짐..      0\n",
              "103572   6822058       마눌님도 자고, 우리 애도 자고 결국엔 끝나기 20분전에 도망치듯 빠져나왔다..      0\n",
              "102382   9837833                                       시나리오 수준이 참..      0\n",
              "133343   5879324     2004년꺼를 이제 가지고와서 어쩌겟다는거지? 지금시대에 이런영화가 인정받을것같아?      0\n",
              "...          ...                                                ...    ...\n",
              "37514    8494235  끝난 후에도 계속해서 잔잔하게 밀려오는 감동과 여운.. 특히 여주의 연기가 좋았고 ...      1\n",
              "90946    8898595                        치밀한 구성 막판이 조금 아쉬웠으나 매우 우수했다      1\n",
              "117818   4405477             이거보고 진짜 감동먹엇어요ㅠㅠ특히 끝나갈때 남자 제자리걸음할때 ~!!      1\n",
              "144608   6991515                                실화를 배경으로 했다고 합니다...      1\n",
              "148841  10002192  원작을 안 읽어서인지 처음 기대한 건 유카와와 이시가미의 대결구도였다. 기대했던 건...      1\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXLT6tAdaA34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36851797-c2aa-440a-c8a6-f4fc97bf025c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    500\n",
              "1    500\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "# 검증\n",
        "\n",
        "sample_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLNUjgawLnJ1"
      },
      "source": [
        "### CustomClassifier 클래스 구현\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_bertclf.png?raw=true\" width=400>\n",
        "\n",
        "- 그림과 같이 사전 학습(pre-trained)된 `BERT` 모델을 불러와 그 위에 **1 hidden layer**와 **binary classifier layer**를 쌓아 fine-tunning 모델을 생성할 것이다.    \n",
        "---\n",
        "- hidden layer 1개와 output layer(binary classifier layer)를 갖는 `CustomClassifier` 클래스를 구현하라.\n",
        "- 클래스 정의\n",
        "  - 생성자 입력 매개변수\n",
        "    - `hidden_size` : BERT의 embedding size\n",
        "    - `n_label` : class(label) 개수\n",
        "  - 생성자에서 생성할 변수\n",
        "    - `bert` : BERT 모델 인스턴스 \n",
        "    - `classifier` : 1 hidden layer + relu +  dropout + classifier layer를 stack한 `nn.Sequential` 모델\n",
        "      - 첫번재 히든 레이어 (첫번째 `nn.Linear`)\n",
        "        - input: BERT의 마지막 layer의 1번재 token ([CLS] 토큰) (shape: `hidden_size`)\n",
        "        - output: (shape: `linear_layer_hidden_size`)\n",
        "      - 아웃풋 레이어 (두번째 `nn.Linear`)\n",
        "        - input: 첫번째 히든 레이어의 아웃풋 (shape: `linear_layer_hidden_size`)\n",
        "        - output: target/label의 개수 (shape:2)\n",
        "  - 메소드\n",
        "    - `forward()`\n",
        "      - BERT output에서 마지막 레이어의 첫번째 토큰 ('[CLS]')의 embedding을 가져와 `self.classifier`에 입력해 아웃풋으로 logits를 출력함.\n",
        "  - 주의 사항\n",
        "    - `CustomClassifier` 클래스는 부모 클래스로 `nn.Module`을 상속 받는다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0WbqVv62Zvy"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im98H4-U1eQQ"
      },
      "outputs": [],
      "source": [
        "# classifier 구현\n",
        "class CustomClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size: int, n_label: int):\n",
        "    super(CustomClassifier, self).__init__()\n",
        "\n",
        "    self.bert = BertModel.from_pretrained(\"klue/bert-base\") # bert model instance\n",
        "\n",
        "    dropout_rate = 0.1\n",
        "    linear_layer_hidden_size = 32\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, linear_layer_hidden_size), # 1 hidden Layer(nn.Linear)\n",
        "        nn.ReLU(), # ReLu\n",
        "        nn.Dropout(dropout_rate), # Dropout: 신경망 구조 학습시, 레이어간 연결 중 일부 랜덤하게 삭제, 여러개의 네트워크 앙상블 효과 => 일반화 성능 up\n",
        "        nn.Linear(linear_layer_hidden_size, 2) # Classifier Layer\n",
        "    ) # torch.nn에서 제공되는 Sequential, Linear, ReLU, Dropout 함수 활용\n",
        "\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "    outputs = self.bert(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids,\n",
        "    )\n",
        "\n",
        "    # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱\n",
        "    cls_token_last_hidden_states = outputs['pooler_output']\n",
        "    # 마지막 layer의 첫 번째 토큰 (\"[CLS]\") 벡터를 가져오기, shape = (1, hidden_size)\n",
        "\n",
        "    logits = self.classifier(cls_token_last_hidden_states)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x7PU1t1LnJ1"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXesCG5TLnJ1"
      },
      "source": [
        "### 학습 데이터를 배치 단위로 저장하는 이터레이터 함수 `data_iterator` 구현\n",
        "- 데이터 프레임을 입력 받아 text를 \b토큰 id로 변환하고 label은 텐서로 변환해 배치만큼 잘라 (input, \btarget) 튜플 형태의 이터레이터를 생성하는 `data_iterator` 함수를 구현하라.\n",
        "- 함수 정의 \n",
        "  - 입력 매개변수\n",
        "    - `input_column` : text 데이터 column 명\n",
        "    - `target_column` : label 데이터 column 명\n",
        "    -  `batch_size` : 배치 사이즈\n",
        "  - 조건\n",
        "    - 함수는 다음을 수행해야 함 \n",
        "      - 데이터 프레임 랜덤 셔플링\n",
        "      - `tokenizer_bert`로 text를 token_id로 변환 + 텐서화 \n",
        "      - target(label)을 텐서화\n",
        "  - 반환값 \n",
        "    - (input, target) 튜플 형태의 이터레이터를 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-tJERGI4Fzk",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5782b72-ce13-47bc-bef6-7ad831f163d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlcYCOyW3d2t"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_U_c-Mf3d2t"
      },
      "outputs": [],
      "source": [
        "tokenizer_bert = BertTokenizer.from_pretrained(\"klue/bert-base\") # lower-cased version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2VnIY-ALnJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fd5827-8cfd-423e-9e91-da627df8c72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: 심형래 영화보다 재미없나?...\n",
            "\n",
            "Tokenized Sentence: {'input_ids': tensor([[    2,  1331,  2444,  2315,  3771,  2178,  2062, 19113,  2075,    35,\n",
            "            18,    18,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "# 토크나이징 예시 (1개의 문장)\n",
        "\n",
        "# 1. string type의 문장을 가져옴\n",
        "ex_sent = sample_df.document.iloc[0]\n",
        "print(f\"Original Sentence: {ex_sent}\\n\")\n",
        "\n",
        "# 2. 문장을 토크나이즈 함. 이 때, 특수 토큰 (\"[CLS]\", \"[SPE]\")을 자동으로 추가하고 pytorch의 tensor형태로 변환해 반환함\n",
        "tensor_sent = tokenizer_bert(\n",
        "    ex_sent,\n",
        "    add_special_tokens=True, # 문장의 앞에 문장 시작을 알리는 \"[CLS]\"토큰, 문장의 끝에 문장 끝을 알리는 \"[SPE]\"토큰을 자동으로 추가\n",
        "    return_tensors='pt' # pytorch tensor로 반환할 것\n",
        ")\n",
        "print(f\"Tokenized Sentence: {tensor_sent}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtXP_wRFLnJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0131e75-92e8-4292-b683-4bedca531235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence 1: 심형래 영화보다 재미없나?...\n",
            "Original Sentence 2: 정말 지루하네.. 감상적인 장면이 너무 필요 이상으로 많아서 흥미가 너무 떨어짐..\n",
            "\n",
            "Tokenized Sentence list: {'input_ids': tensor([[    2,  1331,  2444,  2315,  3771,  2178,  2062, 19113,  2075,    35,\n",
            "            18,    18,    18,     3,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0],\n",
            "        [    2,  3944,  9734,  2205,  2203,    18,    18,  7397, 31221,  5034,\n",
            "          2052,  3760,  3677,  3658,  6233,  1039,  2227,  2112,  5800,  2116,\n",
            "          3760,  3928,  2719,    18,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "# 토크나이징 예시 (2개의 문장)\n",
        "\n",
        "# 1. 2개의 문장을 가진 list 생성\n",
        "ex_sent_list = list(sample_df.document.iloc[:2].values)\n",
        "for i, sent in enumerate(ex_sent_list):\n",
        "    print(f\"Original Sentence {i+1}: {sent}\")\n",
        "\n",
        "# 2. 문장 리스트를 토크나이즈 함. 이 때, 리스트 내 문장들의 토큰 길이가 동일할 수 있도록 가장 긴 문장을 기준으로 부족한 위치에 \"[PAD]\" 토큰을 추가\n",
        "tensor_sent_list = tokenizer_bert(\n",
        "    ex_sent_list,\n",
        "    add_special_tokens=True, # Whether or not to encode the sequences with the special tokens relative to their model.\n",
        "    return_tensors='pt',\n",
        "    padding=\"longest\" # 가장 긴 문장을 기준으로 token개수를 맞춤. 모자란 토큰 위치는 \"[PAD]\" 토큰을 추가\n",
        ")\n",
        "\n",
        "print(f\"\\nTokenized Sentence list: {tensor_sent_list}\")\n",
        "\n",
        "# 토크나이즈 된 두 문장의 길이가 동일함을 검증\n",
        "assert tensor_sent_list['input_ids'][0].shape == tensor_sent_list['input_ids'][1].shape "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(frac=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "m1VrfDKW0gDf",
        "outputId": "a9e75b86-1123-48cf-a5f6-d5833e913d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-14e959e4-dcd9-47d6-a3ee-275a62340ec6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>137386</th>\n",
              "      <td>10113855</td>\n",
              "      <td>생각보다 훨씬 잘만들고 재미있는영화 어느것 하나 빠지지 않는다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57104</th>\n",
              "      <td>417589</td>\n",
              "      <td>음 왜 봤을까?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104732</th>\n",
              "      <td>7053421</td>\n",
              "      <td>재밌다. 오래전에 우연히 고른 만화책으로 먼저 봤었는데 ~ 영화화되다니 정말 감회가...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48340</th>\n",
              "      <td>4970957</td>\n",
              "      <td>\"&lt;김약국의 딸들&gt;인데 제목이 틀리구나 네이버야!! \"\"나이브\"\" 대사 인상적이었음\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53674</th>\n",
              "      <td>7123337</td>\n",
              "      <td>-_-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129599</th>\n",
              "      <td>3449098</td>\n",
              "      <td>비디오로는속귀타귀로봤는데, 실망.....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116706</th>\n",
              "      <td>7466052</td>\n",
              "      <td>SF를 좋아한다면 사랑하지 않을 수 없는 작품!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5893</th>\n",
              "      <td>9701547</td>\n",
              "      <td>시나리오 배우 최고 영화 보실분들은 줄거리 보지마세요ㅋㅋ스포대박ㅋㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88375</th>\n",
              "      <td>10253432</td>\n",
              "      <td>하아 유플티비로 보는데 나레이션 때문에 끝까지 못보겠어요</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61180</th>\n",
              "      <td>2453808</td>\n",
              "      <td>소재만 특이했던 영화.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149995 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14e959e4-dcd9-47d6-a3ee-275a62340ec6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14e959e4-dcd9-47d6-a3ee-275a62340ec6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14e959e4-dcd9-47d6-a3ee-275a62340ec6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              id                                           document  label\n",
              "137386  10113855                 생각보다 훨씬 잘만들고 재미있는영화 어느것 하나 빠지지 않는다      1\n",
              "57104     417589                                           음 왜 봤을까?      0\n",
              "104732   7053421  재밌다. 오래전에 우연히 고른 만화책으로 먼저 봤었는데 ~ 영화화되다니 정말 감회가...      1\n",
              "48340    4970957    \"<김약국의 딸들>인데 제목이 틀리구나 네이버야!! \"\"나이브\"\" 대사 인상적이었음\"      1\n",
              "53674    7123337                                                -_-      0\n",
              "...          ...                                                ...    ...\n",
              "129599   3449098                             비디오로는속귀타귀로봤는데, 실망.....      0\n",
              "116706   7466052                         SF를 좋아한다면 사랑하지 않을 수 없는 작품!      1\n",
              "5893     9701547             시나리오 배우 최고 영화 보실분들은 줄거리 보지마세요ㅋㅋ스포대박ㅋㅋㅋ      1\n",
              "88375   10253432                    하아 유플티비로 보는데 나레이션 때문에 끝까지 못보겠어요      0\n",
              "61180    2453808                                       소재만 특이했던 영화.      0\n",
              "\n",
              "[149995 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38RLJVTS8TQf",
        "outputId": "016e763f-022f-4518-97bf-91989fa14bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           int64\n",
              "document    object\n",
              "label        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR22xs-xf1QH"
      },
      "outputs": [],
      "source": [
        "def data_iterator(df, input_column, target_column, batch_size):\n",
        "  \"\"\"\n",
        "  데이터 프레임을 셔플한 후 \n",
        "  데이터 프레임의 input_column을 batch_size만큼 잘라 토크나이즈 + 텐서화하고, target_column을 batch_size만큼 잘라 텐서화 하여\n",
        "  (input, output) 튜플 형태의 이터레이터를 생성\n",
        "  \"\"\"\n",
        "\n",
        "  global tokenizer_bert\n",
        "\n",
        "  # 1. 데이터 프레임 셔플\n",
        "  #    pandas의 sample 함수 사용\n",
        "  df = df.sample(frac=1)\n",
        "\n",
        "  # 2. 이터레이터 생성\n",
        "  for idx in range(0, df.shape[0], batch_size):\n",
        "    batch_df = df.sample(int(batch_size), random_state=7777) # batch_size만큼 데이터 추출\n",
        "    \n",
        "    tensorized_input = tokenizer_bert(list(batch_df[input_column].values), return_tensors='pt', padding=\"longest\") # df의 text를 토크나이징 + token id로 변환 + 텐서화 (df의 input_column 사용)\n",
        "\n",
        "    tensorized_target = torch.from_numpy(np.array(batch_df[target_column])) # target(label)을 텐서화 (df의 target_column 사용)\n",
        "    \n",
        "    yield tensorized_input, tensorized_target # 튜플 형태로 yield"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTlAV0hqILmc"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9VNAMchf1QI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97dd3c3c-749c-4785-947b-088c4b0d02e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_ids': tensor([[   2, 5124,  732,  ...,    0,    0,    0],\n",
              "         [   2, 1235, 2295,  ...,    0,    0,    0],\n",
              "         [   2,  801, 2031,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [   2, 6077, 3676,  ...,    0,    0,    0],\n",
              "         [   2, 4647, 5489,  ...,    0,    0,    0],\n",
              "         [   2, 8354, 2255,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]])},\n",
              " tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "         0, 1, 1, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "next(train_iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqnp2Q6ZLnJ2"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQVTqAUxLnJ2"
      },
      "source": [
        "### `data_iterator` 함수로 생성한 이터레이터를 for loop 돌면서 배치 단위의 데이터를 모델에 학습하는 `train()` 함수 구현\n",
        "- 함수 정의\n",
        "  - 입력 매개변수\n",
        "    - `model` : BERT + 1 hidden layer classifier 모델\n",
        "    - `data_iterator` : train data iterator\n",
        "- Reference\n",
        "  - [Loss: CrossEntropyLoss official document](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "  - [Optimizer: AdamW official document](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sE7xjYcRD1p"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from numpy.core.fromnumeric import nonzero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Er1qKtsf1QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795bee6c-34a0-4a35-bd96-e03d5968b335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# 모델 클래스 정의\n",
        "model = CustomClassifier(hidden_size=768, n_label=2)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# 데이터 이터레이터 정의 \n",
        "train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)\n",
        "\n",
        "# 로스 및 옵티마이저\n",
        "loss_fct = CrossEntropyLoss()\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,\n",
        "    eps=1e-8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvY5rxDKHQAp"
      },
      "outputs": [],
      "source": [
        "def train(model, data_iterator):\n",
        "\n",
        "  global loss_fct # 위에서 정의한 loss 함수\n",
        "\n",
        "  # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "  total_loss, batch_loss, batch_count = 0,0,0\n",
        "  \n",
        "  # model을 train 모드로 설정 & device 할당\n",
        "  model.train()\n",
        "  model.to(device)\n",
        "  \n",
        "  # data iterator를 돌면서 하나씩 학습\n",
        "  for step, batch in enumerate(data_iterator):\n",
        "    ## *** data_iterator 의 step, batch\n",
        "    batch_count+=1\n",
        "    print('step', step)\n",
        "\n",
        "    # tensor 연산 전, 각 tensor에 device 할당\n",
        "    ## ***'list' object has no attribute 'to'\n",
        "    batch = tuple(item.to(device) for item in batch)\n",
        "    print('batch-item {batch}-{item}')\n",
        "    \n",
        "    batch_input, batch_label = batch\n",
        "    \n",
        "    # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "    model.zero_grad()\n",
        "    \n",
        "    # forward\n",
        "    logits = model(batch_input['input_ids'], batch_input['attention_mask'], batch_input['token_type_ids'])\n",
        "\n",
        "    # loss\n",
        "    # loss = loss_fct(None, None)\n",
        "    loss = loss_fct(logits,batch_label)\n",
        "    batch_loss += loss.item()\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "    loss.backward()\n",
        "    \n",
        "    # optimizer 업데이트\n",
        "    optimizer.step()\n",
        "      \n",
        "    # 배치 10개씩 처리할 때마다 평균 loss를 출력\n",
        "    if (step % 10 == 0 and step != 0):\n",
        "      print(f\"Step : {step}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "      \n",
        "      # 변수 초기화 \n",
        "      batch_loss, batch_count = 0,0\n",
        "  \n",
        "  print(f\"Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "  print(\"Train Finished\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEYo8z9RLnJ2"
      },
      "source": [
        "### 지금까지 구현한 함수와 클래스를 모두 불러와 `train()` 함수를 실행하자\n",
        "- fine-tuning 모델 클래스 (`CustomClassifier`)\n",
        "    - hidden_size = 768\n",
        "    - n_label = 2\n",
        "- 데이터 이터레이터 함수 (`data_iterator`)\n",
        "    - batch_size = 32\n",
        "- loss \n",
        "    - `CrossEntropyLoss()`\n",
        "- optimizer\n",
        "    - optimizer는 loss(오차)를 상쇄하기 위해 파라미터를 업데이트 하는 과정\n",
        "    - `optimizer.step()` 시 파라미터가 업데이트 됨 \n",
        "    - lr = 2e-5\n",
        "- Reference\n",
        "  - [Optimizer 종류 설명 한국어 블로그 ](https://ganghee-lee.tistory.com/24)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCODIxCfFEDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5807cb46-b5e4-4285-dea6-1fb660eae39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0\n",
            "batch-item {batch}-{item}\n",
            "step 1\n",
            "batch-item {batch}-{item}\n",
            "step 2\n",
            "batch-item {batch}-{item}\n",
            "step 3\n",
            "batch-item {batch}-{item}\n",
            "step 4\n",
            "batch-item {batch}-{item}\n",
            "step 5\n",
            "batch-item {batch}-{item}\n",
            "step 6\n",
            "batch-item {batch}-{item}\n",
            "step 7\n",
            "batch-item {batch}-{item}\n",
            "step 8\n",
            "batch-item {batch}-{item}\n",
            "step 9\n",
            "batch-item {batch}-{item}\n",
            "step 10\n",
            "batch-item {batch}-{item}\n",
            "Step : 10, Avg Loss : 0.4880\n",
            "step 11\n",
            "batch-item {batch}-{item}\n",
            "step 12\n",
            "batch-item {batch}-{item}\n",
            "step 13\n",
            "batch-item {batch}-{item}\n",
            "step 14\n",
            "batch-item {batch}-{item}\n",
            "step 15\n",
            "batch-item {batch}-{item}\n",
            "step 16\n",
            "batch-item {batch}-{item}\n",
            "step 17\n",
            "batch-item {batch}-{item}\n",
            "step 18\n",
            "batch-item {batch}-{item}\n",
            "step 19\n",
            "batch-item {batch}-{item}\n",
            "step 20\n",
            "batch-item {batch}-{item}\n",
            "Step : 20, Avg Loss : 0.2060\n",
            "step 21\n",
            "batch-item {batch}-{item}\n",
            "step 22\n",
            "batch-item {batch}-{item}\n",
            "step 23\n",
            "batch-item {batch}-{item}\n",
            "step 24\n",
            "batch-item {batch}-{item}\n",
            "step 25\n",
            "batch-item {batch}-{item}\n",
            "step 26\n",
            "batch-item {batch}-{item}\n",
            "step 27\n",
            "batch-item {batch}-{item}\n",
            "step 28\n",
            "batch-item {batch}-{item}\n",
            "step 29\n",
            "batch-item {batch}-{item}\n",
            "step 30\n",
            "batch-item {batch}-{item}\n",
            "Step : 30, Avg Loss : 0.1109\n",
            "step 31\n",
            "batch-item {batch}-{item}\n",
            "Mean Loss : 0.2692\n",
            "Train Finished\n"
          ]
        }
      ],
      "source": [
        "# 학습 시작\n",
        "train(model, train_iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37UbAkh7LnJ3"
      },
      "source": [
        "## fine-tuning 2가지 방법론 비교\n",
        "- pre-trained BERT 모델 파라미터를 **freeze**한 채 학습하라\n",
        "    - BERT의 파라미터의 `requires_grad` 값을 `False`로 바꾸면, 학습 시 BERT의 파라미터는 미분이 계산되지도, 업데이트 되지도 않는다. \n",
        "    - 이렇게 특정 모델의 파라미터가 업데이트 하지 못하도록 설정하는 것을 **freeze**라고 한다. \n",
        "    - BERT 파라미터를 freeze시킨 채 학습을 진행해보자. 이럴 경우, 우리가 직접 쌓은 fine-tuning layer의 파라미터만 업데이트 된다. \n",
        "- **unfreeze**와 **freeze** 모델의 성능을 비교해 보자. 어떤 방식이 더 우수한가?\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld260K3YLnJ3"
      },
      "outputs": [],
      "source": [
        "class CustomClassifierFreezed(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size: int, n_label: int):\n",
        "    super(CustomClassifierFreezed, self).__init__()\n",
        "\n",
        "    self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n",
        "    # freeze BERT parameter\n",
        "    # BERT의 파라미터는 고정값으로 두고 BERT 위에 씌운 linear layer의 파라미터만 학습하려고 한다. \n",
        "    # 이 경우, BERT의 파라미터의 'requires_grad' 값을 False로 변경해줘야 학습 시 해당 파라미터의 미분값이 계산되지 않는다.\n",
        "    for param in self.bert.parameters():\n",
        "        param.requires_grad = False \n",
        "\n",
        "    dropout_rate = 0.1\n",
        "    linear_layer_hidden_size = 32\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, linear_layer_hidden_size), # 1 hidden Layer(nn.Linear)\n",
        "        nn.ReLU(), # ReLu\n",
        "        nn.Dropout(dropout_rate), # Dropout: 신경망 구조 학습시, 레이어간 연결 중 일부 랜덤하게 삭제, 여러개의 네트워크 앙상블 효과 => 일반화 성능 up\n",
        "        nn.Linear(linear_layer_hidden_size, 2)\n",
        "    )\n",
        "\n",
        "      \n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "    outputs = self.bert(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids,\n",
        "    )\n",
        "    \n",
        "    # BERT 모델의 마지막 레이어의 첫번재 토큰을 인덱싱\n",
        "    cls_token_last_hidden_states = outputs['pooler_output'] # 마지막 layer의 첫 번째 토큰 (\"[CLS]\") 벡터를 가져오기, shape = (1, hidden_size)\n",
        "    logits = self.classifier(cls_token_last_hidden_states)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ClEEHB6F6LW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54861bc-f41e-405b-8469-9ef5401655d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# freeze 모델\n",
        "# model을 제외한 설정값은 \b위에서 실행한 unfreeze 모델과 동일\n",
        "model = CustomClassifierFreezed(hidden_size=768, n_label=2)\n",
        "\n",
        "# 데이터 이터레이터\n",
        "batch_size = 32\n",
        "train_iterator = data_iterator(sample_df, 'document', 'label', batch_size)\n",
        "\n",
        "# 로스 및 옵티마이저\n",
        "loss_fct = CrossEntropyLoss()\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,\n",
        "    eps=1e-8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqcPcWZeLnJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6d1ebe-f909-44dd-a9ab-f6922ddd72a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0\n",
            "batch-item {batch}-{item}\n",
            "step 1\n",
            "batch-item {batch}-{item}\n",
            "step 2\n",
            "batch-item {batch}-{item}\n",
            "step 3\n",
            "batch-item {batch}-{item}\n",
            "step 4\n",
            "batch-item {batch}-{item}\n",
            "step 5\n",
            "batch-item {batch}-{item}\n",
            "step 6\n",
            "batch-item {batch}-{item}\n",
            "step 7\n",
            "batch-item {batch}-{item}\n",
            "step 8\n",
            "batch-item {batch}-{item}\n",
            "step 9\n",
            "batch-item {batch}-{item}\n",
            "step 10\n",
            "batch-item {batch}-{item}\n",
            "Step : 10, Avg Loss : 0.6803\n",
            "step 11\n",
            "batch-item {batch}-{item}\n",
            "step 12\n",
            "batch-item {batch}-{item}\n",
            "step 13\n",
            "batch-item {batch}-{item}\n",
            "step 14\n",
            "batch-item {batch}-{item}\n",
            "step 15\n",
            "batch-item {batch}-{item}\n",
            "step 16\n",
            "batch-item {batch}-{item}\n",
            "step 17\n",
            "batch-item {batch}-{item}\n",
            "step 18\n",
            "batch-item {batch}-{item}\n",
            "step 19\n",
            "batch-item {batch}-{item}\n",
            "step 20\n",
            "batch-item {batch}-{item}\n",
            "Step : 20, Avg Loss : 0.6690\n",
            "step 21\n",
            "batch-item {batch}-{item}\n",
            "step 22\n",
            "batch-item {batch}-{item}\n",
            "step 23\n",
            "batch-item {batch}-{item}\n",
            "step 24\n",
            "batch-item {batch}-{item}\n",
            "step 25\n",
            "batch-item {batch}-{item}\n",
            "step 26\n",
            "batch-item {batch}-{item}\n",
            "step 27\n",
            "batch-item {batch}-{item}\n",
            "step 28\n",
            "batch-item {batch}-{item}\n",
            "step 29\n",
            "batch-item {batch}-{item}\n",
            "step 30\n",
            "batch-item {batch}-{item}\n",
            "Step : 30, Avg Loss : 0.6645\n",
            "step 31\n",
            "batch-item {batch}-{item}\n",
            "Mean Loss : 0.6708\n",
            "Train Finished\n"
          ]
        }
      ],
      "source": [
        "# 학습 시작\n",
        "train(model, train_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K5kXWvjL8FJa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "진혜정 - Week2_2_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}